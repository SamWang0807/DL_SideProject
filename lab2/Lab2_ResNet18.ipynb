{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f8d6ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as data\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5cd3c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA_PATH =  \"./test\"\n",
    "TRAIN_DATA_PATH = \"./train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5586bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transform, you can add different transform methods\n",
    "img_size = 224\n",
    "torch.manual_seed(0)\n",
    "train_transform = transforms.Compose([transforms.Resize((img_size,img_size)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "\n",
    "train_aug0 = transforms.Compose([\n",
    "                                    transforms.RandomResizedCrop(224),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "train_aug1 = transforms.Compose([transforms.Resize((img_size,img_size)),\n",
    "                                    transforms.RandomAffine(0,scale=(0.7,1.2)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "\n",
    "train_aug2 = transforms.Compose([transforms.Resize((img_size,img_size)),\n",
    "                                    transforms.transforms.RandomRotation(25),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize((img_size,img_size)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "\n",
    "dataset_aug0 = datasets.ImageFolder(root=TRAIN_DATA_PATH,transform=train_aug0)\n",
    "dataset_aug1 = datasets.ImageFolder(root=TRAIN_DATA_PATH,transform=train_aug1)\n",
    "dataset_aug2 = datasets.ImageFolder(root=TRAIN_DATA_PATH,transform=train_aug2)\n",
    "dataset_orig = datasets.ImageFolder(root=TRAIN_DATA_PATH,transform=train_transform)\n",
    "\n",
    "dataset = data.ConcatDataset([dataset_orig, dataset_aug0, dataset_aug1, dataset_aug2])\n",
    "test_data = datasets.ImageFolder(root=TEST_DATA_PATH,transform=test_transform)\n",
    "\n",
    "# spilt data into training and validation\n",
    "TOTAL_SIZE = len(dataset)\n",
    "ratio = 0.9\n",
    "train_len = round(TOTAL_SIZE * ratio)\n",
    "val_len = round(TOTAL_SIZE * (1-ratio))\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_len, val_len])\n",
    "\n",
    "# data loader, you can choose the input arguments by yourself\n",
    "\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True,  num_workers=4)\n",
    "val_data_loader = data.DataLoader(val_dataset, batch_size=128, shuffle=True,  num_workers=4)\n",
    "test_data_loader  = data.DataLoader(test_data, batch_size=8, shuffle=False, num_workers=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2635b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self,basicblock,num_classes=5):\n",
    "    \n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1=nn.Sequential(BasicBlock(inplanes=64, planes=64, stride=1),BasicBlock(inplanes=64, planes=64, stride=1))\n",
    "        self.layer2=nn.Sequential(BasicBlock(inplanes=64, planes=128, stride=2),BasicBlock(inplanes=128, planes=128, stride=1))\n",
    "        self.layer3=nn.Sequential(BasicBlock(inplanes=128, planes=256, stride=2),BasicBlock(inplanes=256, planes=256, stride=1))\n",
    "        self.layer4=nn.Sequential(BasicBlock(inplanes=256, planes=512, stride=2),BasicBlock(inplanes=512, planes=512, stride=1))\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512,5)\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "836ec193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes,kernel_size=3,stride=stride,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = None\n",
    "        if(stride==2):\n",
    "            self.downsample = nn.Sequential(nn.Conv2d(inplanes, planes,kernel_size=1,stride=2),nn.BatchNorm2d(planes))\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8be7eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d46c3bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 |Train Loss:  1.2618 |Train Acc:50.7762 |Val Loss:  1.0455 |Val Acc:55.3191\n",
      "-------------saving model--------------\n",
      "Epoch:  2 |Train Loss:  1.0311 |Train Acc:57.8299 |Val Loss:  1.0731 |Val Acc:55.1672\n",
      "Epoch:  3 |Train Loss:  0.9862 |Train Acc:59.6186 |Val Loss:  1.0144 |Val Acc:60.3343\n",
      "-------------saving model--------------\n",
      "Epoch:  4 |Train Loss:  0.9567 |Train Acc:62.0823 |Val Loss:  0.9695 |Val Acc:63.3739\n",
      "-------------saving model--------------\n",
      "Epoch:  5 |Train Loss:  0.9586 |Train Acc:60.7830 |Val Loss:  1.1413 |Val Acc:58.0547\n",
      "Epoch:  6 |Train Loss:  0.9459 |Train Acc:62.7405 |Val Loss:  1.0869 |Val Acc:57.7508\n",
      "Epoch:  7 |Train Loss:  0.8915 |Train Acc:64.4786 |Val Loss:  0.8319 |Val Acc:67.4772\n",
      "-------------saving model--------------\n",
      "Epoch:  8 |Train Loss:  0.8850 |Train Acc:65.2886 |Val Loss:  0.8497 |Val Acc:64.4377\n",
      "Epoch:  9 |Train Loss:  0.8382 |Train Acc:66.3854 |Val Loss:  0.9893 |Val Acc:65.6535\n",
      "Epoch: 10 |Train Loss:  0.8305 |Train Acc:67.5329 |Val Loss:  0.8052 |Val Acc:66.8693\n",
      "-------------saving model--------------\n",
      "Epoch: 11 |Train Loss:  0.8276 |Train Acc:67.9379 |Val Loss:  0.8483 |Val Acc:66.1094\n",
      "Epoch: 12 |Train Loss:  0.8223 |Train Acc:68.2585 |Val Loss:  0.8005 |Val Acc:68.9970\n",
      "-------------saving model--------------\n",
      "Epoch: 13 |Train Loss:  0.7947 |Train Acc:69.6591 |Val Loss:  0.8516 |Val Acc:68.9970\n",
      "Epoch: 14 |Train Loss:  0.7751 |Train Acc:70.2160 |Val Loss:  0.8198 |Val Acc:68.6930\n",
      "Epoch: 15 |Train Loss:  0.7910 |Train Acc:69.6591 |Val Loss:  1.0143 |Val Acc:63.2219\n",
      "Epoch: 16 |Train Loss:  0.7607 |Train Acc:70.1822 |Val Loss:  0.7324 |Val Acc:72.4924\n",
      "-------------saving model--------------\n",
      "Epoch: 17 |Train Loss:  0.7378 |Train Acc:71.7516 |Val Loss:  0.7108 |Val Acc:70.9726\n",
      "-------------saving model--------------\n",
      "Epoch: 19 |Train Loss:  0.6995 |Train Acc:73.1691 |Val Loss:  0.9677 |Val Acc:64.2857\n",
      "Epoch: 20 |Train Loss:  0.6857 |Train Acc:73.5235 |Val Loss:  0.7667 |Val Acc:71.8845\n",
      "Epoch: 21 |Train Loss:  0.6727 |Train Acc:73.8947 |Val Loss:  0.7723 |Val Acc:69.7568\n",
      "Epoch: 22 |Train Loss:  0.6771 |Train Acc:74.2997 |Val Loss:  0.6604 |Val Acc:74.6201\n",
      "-------------saving model--------------\n",
      "Epoch: 23 |Train Loss:  0.6618 |Train Acc:74.9409 |Val Loss:  0.7565 |Val Acc:70.3647\n",
      "Epoch: 24 |Train Loss:  0.6591 |Train Acc:74.7553 |Val Loss:  0.6449 |Val Acc:74.7720\n",
      "-------------saving model--------------\n",
      "Epoch: 25 |Train Loss:  0.6602 |Train Acc:74.6034 |Val Loss:  0.9106 |Val Acc:64.4377\n",
      "Epoch: 26 |Train Loss:  0.6271 |Train Acc:76.1559 |Val Loss:  0.6654 |Val Acc:73.2523\n",
      "Epoch: 27 |Train Loss:  0.5820 |Train Acc:77.5397 |Val Loss:  0.7137 |Val Acc:73.1003\n",
      "Epoch: 28 |Train Loss:  0.6163 |Train Acc:76.4259 |Val Loss:  0.5613 |Val Acc:75.6839\n",
      "-------------saving model--------------\n",
      "Epoch: 29 |Train Loss:  0.5972 |Train Acc:77.7253 |Val Loss:  0.5523 |Val Acc:74.6201\n",
      "-------------saving model--------------\n",
      "Epoch: 30 |Train Loss:  0.5818 |Train Acc:77.6409 |Val Loss:  0.6065 |Val Acc:76.4438\n",
      "Epoch: 31 |Train Loss:  0.5508 |Train Acc:78.8559 |Val Loss:  0.6332 |Val Acc:75.5319\n",
      "Epoch: 32 |Train Loss:  0.5309 |Train Acc:78.9571 |Val Loss:  0.6858 |Val Acc:74.3161\n",
      "Epoch: 33 |Train Loss:  0.5100 |Train Acc:80.3240 |Val Loss:  0.6123 |Val Acc:76.4438\n",
      "Epoch: 34 |Train Loss:  0.5055 |Train Acc:80.5096 |Val Loss:  0.6593 |Val Acc:73.4043\n",
      "Epoch: 35 |Train Loss:  0.5292 |Train Acc:79.8515 |Val Loss:  0.8143 |Val Acc:71.1246\n",
      "Epoch: 36 |Train Loss:  0.4876 |Train Acc:80.9990 |Val Loss:  0.5315 |Val Acc:79.9392\n",
      "-------------saving model--------------\n",
      "Epoch: 37 |Train Loss:  0.4593 |Train Acc:82.0790 |Val Loss:  0.3915 |Val Acc:82.8267\n",
      "-------------saving model--------------\n",
      "Epoch: 38 |Train Loss:  0.4371 |Train Acc:83.3446 |Val Loss:  0.4624 |Val Acc:82.5228\n",
      "Epoch: 39 |Train Loss:  0.4380 |Train Acc:83.0240 |Val Loss:  0.4819 |Val Acc:80.5471\n",
      "Epoch: 40 |Train Loss:  0.4182 |Train Acc:84.4414 |Val Loss:  0.3972 |Val Acc:83.2827\n",
      "Epoch: 41 |Train Loss:  0.4088 |Train Acc:84.3908 |Val Loss:  0.4401 |Val Acc:83.7386\n",
      "Epoch: 42 |Train Loss:  0.3821 |Train Acc:85.2346 |Val Loss:  0.3887 |Val Acc:85.2584\n",
      "-------------saving model--------------\n",
      "Epoch: 43 |Train Loss:  0.3942 |Train Acc:85.2346 |Val Loss:  0.5022 |Val Acc:83.4347\n",
      "Epoch: 44 |Train Loss:  0.3730 |Train Acc:85.5383 |Val Loss:  0.5707 |Val Acc:79.3313\n",
      "Epoch: 45 |Train Loss:  0.3916 |Train Acc:85.0321 |Val Loss:  0.3667 |Val Acc:85.5623\n",
      "-------------saving model--------------\n",
      "Epoch: 46 |Train Loss:  0.3479 |Train Acc:86.6352 |Val Loss:  0.4189 |Val Acc:85.5623\n",
      "Epoch: 47 |Train Loss:  0.3510 |Train Acc:86.6183 |Val Loss:  0.4578 |Val Acc:82.3708\n",
      "Epoch: 48 |Train Loss:  0.3450 |Train Acc:87.0570 |Val Loss:  0.3140 |Val Acc:86.3222\n",
      "-------------saving model--------------\n",
      "Epoch: 49 |Train Loss:  0.3321 |Train Acc:87.4114 |Val Loss:  0.4445 |Val Acc:81.9149\n",
      "Epoch: 50 |Train Loss:  0.3238 |Train Acc:87.5295 |Val Loss:  0.4053 |Val Acc:84.3465\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(BasicBlock)\n",
    "model.to(device=device)\n",
    "\n",
    "            \n",
    "params_to_update = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(params_to_update, lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# start training \n",
    "epochs = 50\n",
    "\n",
    "min_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_val_loss = 0\n",
    "    train_hit = 0\n",
    "    val_hit = 0\n",
    "    \n",
    "    for data, target in train_data_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output=model(data)\n",
    "        \n",
    "        # loss function\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        train_hit += pred.eq(target.data.view_as(pred)).cpu().sum().item() \n",
    "\n",
    "\n",
    "        # do back propagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #lr_sch.step()    \n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data, target in val_data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            total_val_loss += F.cross_entropy(output, target).item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            val_hit += pred.eq(target.data.view_as(pred)).cpu().sum().item() \n",
    "    \n",
    "    avg_train_loss = total_train_loss/len(train_data_loader)\n",
    "    avg_val_loss   = total_val_loss/len(val_data_loader)\n",
    "    \n",
    "    print('Epoch:%3d'%epoch\n",
    "        , '|Train Loss:%8.4f'%(avg_train_loss)\n",
    "        , '|Train Acc:%3.4f'%(train_hit/len(train_data_loader.dataset)*100.0)\n",
    "        , '|Val Loss:%8.4f'%(avg_val_loss)\n",
    "        , '|Val Acc:%3.4f'%(val_hit/len(val_data_loader.dataset)*100.0))\n",
    "    \n",
    "    if avg_val_loss < min_val_loss:\n",
    "        min_val_loss = avg_val_loss\n",
    "        print(\"-------------saving model--------------\")\n",
    "        # save the model\n",
    "        torch.save(model, \"model.pth\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba38d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load the model so that you don't need to train the model again\n",
    "test_model = torch.load(\"model.pth\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f594a34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,data_loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        correct = 0\n",
    "        bs = test_data_loader.batch_size\n",
    "        result = []\n",
    "        for i, (data, target) in enumerate(test_data_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            arr = pred.data.cpu().numpy()\n",
    "            for j in range(pred.size()[0]):\n",
    "                file_name = test_data.samples[i*bs+j][0].split('/')[-1]\n",
    "                result.append((file_name,pred[j].cpu().numpy()[0]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff3e8864",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test(test_model,test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81c011a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('ID_result.csv','w') as f:\n",
    "    f.write('ID,label\\n')\n",
    "    for data in result:\n",
    "        f.write(data[0]+','+str(data[1])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b85d28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
