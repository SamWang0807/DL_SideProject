{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA_PATH =  \"./test\"\n",
    "TRAIN_DATA_PATH = \"./train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 1646\n",
      "    Root Location: ./train\n",
      "    Transforms (if any): Compose(\n",
      "                             Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "                             ToTensor()\n",
      "                             Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "                         )\n",
      "    Target Transforms (if any): None\n",
      "{'actinic keratosis': 0, 'basal cell carcinoma': 1, 'melanoma': 2, 'nevus': 3, 'pigmented benign keratosis': 4}\n"
     ]
    }
   ],
   "source": [
    "# data transform, you can add different transform methods\n",
    "img_size = 224\n",
    "train_transform = transforms.Compose([\n",
    "                                    transforms.Resize((img_size,img_size)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize((img_size,img_size)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.CenterCrop(10),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=TRAIN_DATA_PATH,transform=train_transform)\n",
    "test_data = datasets.ImageFolder(root=TEST_DATA_PATH,transform=test_transform)\n",
    "\n",
    "# spilt data into training and validation\n",
    "TOTAL_SIZE = len(dataset)\n",
    "ratio = 0.8\n",
    "train_len = round(TOTAL_SIZE * ratio)\n",
    "val_len = round(TOTAL_SIZE * (1-ratio))\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_len, val_len])\n",
    "\n",
    "# data loader, you can choose the input arguments by yourself\n",
    "\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size=32, shuffle=True,  num_workers=4)\n",
    "val_data_loader = data.DataLoader(val_dataset, batch_size=32, shuffle=True,  num_workers=4)\n",
    "test_data_loader  = data.DataLoader(test_data, batch_size=8, shuffle=False, num_workers=4) \n",
    "\n",
    "print(dataset)\n",
    "print(dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 5)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=1e-2\n",
    "epochs = 30\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "lr_sch = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,80], gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 |Train Loss:  1.3516 |Train Acc:42.4450 |Val Loss:  0.8720 |Val Acc:69.9088\n",
      "-------------saving model--------------\n",
      "Epoch:  2 |Train Loss:  0.7753 |Train Acc:71.8299 |Val Loss:  0.6614 |Val Acc:75.6839\n",
      "-------------saving model--------------\n",
      "Epoch:  3 |Train Loss:  0.5861 |Train Acc:80.1822 |Val Loss:  0.5991 |Val Acc:73.5562\n",
      "-------------saving model--------------\n",
      "Epoch:  4 |Train Loss:  0.4174 |Train Acc:85.6492 |Val Loss:  0.5273 |Val Acc:77.8116\n",
      "-------------saving model--------------\n",
      "Epoch:  5 |Train Loss:  0.3039 |Train Acc:89.9772 |Val Loss:  0.5595 |Val Acc:75.6839\n",
      "Epoch:  6 |Train Loss:  0.2397 |Train Acc:93.3181 |Val Loss:  0.4961 |Val Acc:79.0274\n",
      "-------------saving model--------------\n",
      "Epoch:  7 |Train Loss:  0.2009 |Train Acc:94.0774 |Val Loss:  0.5834 |Val Acc:75.3799\n",
      "Epoch:  8 |Train Loss:  0.1765 |Train Acc:94.6090 |Val Loss:  0.5242 |Val Acc:77.2036\n",
      "Epoch:  9 |Train Loss:  0.1524 |Train Acc:94.9127 |Val Loss:  0.5061 |Val Acc:76.5957\n",
      "Epoch: 10 |Train Loss:  0.1343 |Train Acc:95.2923 |Val Loss:  0.5426 |Val Acc:77.8116\n",
      "Epoch: 11 |Train Loss:  0.1111 |Train Acc:96.0516 |Val Loss:  0.5436 |Val Acc:79.6353\n",
      "Epoch: 12 |Train Loss:  0.1101 |Train Acc:95.2923 |Val Loss:  0.5233 |Val Acc:79.3313\n",
      "Epoch: 13 |Train Loss:  0.0910 |Train Acc:95.4442 |Val Loss:  0.5527 |Val Acc:79.0274\n",
      "Epoch: 14 |Train Loss:  0.0869 |Train Acc:95.5201 |Val Loss:  0.5699 |Val Acc:78.1155\n",
      "Epoch: 15 |Train Loss:  0.0901 |Train Acc:95.8238 |Val Loss:  0.6352 |Val Acc:78.1155\n",
      "Epoch: 16 |Train Loss:  0.0984 |Train Acc:94.9886 |Val Loss:  0.6058 |Val Acc:77.8116\n",
      "Epoch: 17 |Train Loss:  0.1004 |Train Acc:95.5961 |Val Loss:  0.6870 |Val Acc:75.9878\n",
      "Epoch: 18 |Train Loss:  0.1394 |Train Acc:94.5330 |Val Loss:  0.6144 |Val Acc:77.2036\n",
      "Epoch: 19 |Train Loss:  0.0978 |Train Acc:95.6720 |Val Loss:  0.5945 |Val Acc:76.2918\n",
      "Epoch: 20 |Train Loss:  0.0793 |Train Acc:95.5961 |Val Loss:  0.6484 |Val Acc:76.5957\n",
      "Epoch: 21 |Train Loss:  0.1003 |Train Acc:95.8238 |Val Loss:  0.6655 |Val Acc:77.8116\n",
      "Epoch: 22 |Train Loss:  0.1294 |Train Acc:95.2164 |Val Loss:  0.5756 |Val Acc:79.6353\n",
      "Epoch: 23 |Train Loss:  0.1327 |Train Acc:94.0015 |Val Loss:  0.5946 |Val Acc:77.5076\n",
      "Epoch: 24 |Train Loss:  0.0801 |Train Acc:96.2794 |Val Loss:  0.6516 |Val Acc:77.2036\n",
      "Epoch: 25 |Train Loss:  0.0799 |Train Acc:96.2035 |Val Loss:  0.5884 |Val Acc:79.6353\n",
      "Epoch: 26 |Train Loss:  0.0799 |Train Acc:96.0516 |Val Loss:  0.5702 |Val Acc:80.2432\n",
      "Epoch: 27 |Train Loss:  0.0736 |Train Acc:95.5961 |Val Loss:  0.6281 |Val Acc:79.3313\n",
      "Epoch: 28 |Train Loss:  0.0678 |Train Acc:95.5201 |Val Loss:  0.5859 |Val Acc:79.0274\n",
      "Epoch: 29 |Train Loss:  0.0732 |Train Acc:95.9757 |Val Loss:  0.6449 |Val Acc:80.8511\n",
      "Epoch: 30 |Train Loss:  0.0689 |Train Acc:96.2794 |Val Loss:  0.6368 |Val Acc:76.8997\n"
     ]
    }
   ],
   "source": [
    "\n",
    "min_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_val_loss = 0\n",
    "    train_hit = 0\n",
    "    val_hit = 0\n",
    "    \n",
    "    for data, target in train_data_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output=model(data)\n",
    "        \n",
    "        # loss function\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        train_hit += pred.eq(target.data.view_as(pred)).cpu().sum().item() \n",
    "\n",
    "\n",
    "        # do back propagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    lr_sch.step()    \n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data, target in val_data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            total_val_loss += F.cross_entropy(output, target).item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            val_hit += pred.eq(target.data.view_as(pred)).cpu().sum().item() \n",
    "    \n",
    "    avg_train_loss = total_train_loss/len(train_data_loader)\n",
    "    avg_val_loss   = total_val_loss/len(val_data_loader)\n",
    "    \n",
    "    print('Epoch:%3d'%epoch\n",
    "        , '|Train Loss:%8.4f'%(avg_train_loss)\n",
    "        , '|Train Acc:%3.4f'%(train_hit/len(train_data_loader.dataset)*100.0)\n",
    "        , '|Val Loss:%8.4f'%(avg_val_loss)\n",
    "        , '|Val Acc:%3.4f'%(val_hit/len(val_data_loader.dataset)*100.0))\n",
    "    \n",
    "    if avg_val_loss < min_val_loss:\n",
    "        min_val_loss = avg_val_loss\n",
    "        print(\"-------------saving model--------------\")\n",
    "        # save the model\n",
    "        torch.save(model, \"model.pth\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
